---
title: "扣子，开源了！"
date: "2025-07-26"
tags: ["开源", "Coze Studio", "Coze Loop", "Docker", "部署指南"]
categories: ["技术", "开源项目"]
description: "扣子宣布开源其核心项目Coze Studio和Coze Loop，并提供详细的部署指南和配置步骤。"
author: "冷逸"
image: ""
---

**核心内容:**
- 扣子开源了Coze Studio和Coze Loop两个核心项目
- 提供了基于Apache2.0协议的开源版本，支持双核CPU+4G内存环境
- 包含完整的Docker部署流程和模型配置说明

**源自** |冷逸沃垠AI 2025-07-26 02:16

![](https://ai.programnotes.cn/img/ai/7c78caa0ba650c3b271ff86c4c7214ed.gif)

夜，是不可能不熬的。 刚刚，扣子宣布开源，主要开源了两个核心项目：

1.Coze Studio（扣子开发平台）

2.Coze Loop（扣子罗盘）

![](https://ai.programnotes.cn/img/ai/a63f7efb4b965320ec8bc0c8ac88649d.png)

GitHub地址: 

https://github.com/coze-dev/coze-studio

https://github.com/coze-dev/cozeloop

Coze Studio是扣子最核心的产品，你可以通过拖拽节点，自由编排任意具有workflow的AI Agent。通过Coze Studio提供的可视化设计与编排工具，开发者可以零代码或低代码，快速打造和调试智能体、应用和工作流。

![](https://ai.programnotes.cn/img/ai/f284fd3ef063d94b62b55c9f209f70d8.png)

Coze Loop是一个面向开发者，专注于AI Agent开发与运维的管理平台。可以帮助开发者更高效地开发和运维AI Agen，比如提示词工程、Agent评测、上线后监控与调优等，提升Agent的运行效果和稳定性。

本次开源，采用极其宽松的Apache2.0协议开源。意味着，所有人都可以免费下载和商用。

安装环境，门槛超低，双核CPU+4G内存即可运行。基本上就是，是个电脑都能使用。

在Agent编排工具领域，Coze一直是独一档的存在。本次开源，可以看到字节Seed团队拥抱开源的决心。

任谁开源，都值得吼两嗓子，感谢扣子，感谢字节。以下，是开源版Coze的安装指南。

## 1.Coze Studio部署指南

环境要求：

![](https://ai.programnotes.cn/img/ai/bcb1cff1e67340a54d82eff5ffd6ef96.png)
- 在安装 Coze Studio 之前，请确保您的机器满足以下最低系统要求： 2 Core、4 GB

- 提前安装 Docker、Docker Compose，并启动 Docker 服务。

部署步骤：

1）获取源码
```
# 克隆代码
git clone https://github.com/coze-dev/coze-studio.git
```

2）配置模型
1. 从模板目录复制doubao-seed-1.6模型的模版文件，并粘贴到配置文件目录。

```
cd coze-studio
# 复制模型配置模版
cp backend/conf/model/template/model_template_ark_doubao-seed-1.6.yaml backend/conf/model/ark_doubao-seed-1.6.yaml
```
1. 在配置文件目录下，修改模版文件。

2. 进入目录 backend/conf/model。打开复制后的文件ark_doubao-seed-1.6.yaml。

3. 设置 id、meta.conn_config.api_key、meta.conn_config.model 字段，并保存文件。

- id：Coze Studio 中的模型 ID，由开发者自行定义，必须是非 0 的整数，且全局唯一。模型上线后请勿修改模型 id 。

- meta.conn_config.api_key：模型服务的 API Key，在本示例中为火山方舟的 API Key，获取方式可参考获取火山方舟 API Key。

- meta.conn_config.model：模型服务的 model ID，在本示例中为火山方舟 doubao-seed-1.6 模型接入点的 Endpoint ID，获取方式可参考获取 Endpoint ID。

3）部署并启动服务

首次部署并启动 Coze Studio 需要拉取镜像、构建本地镜像，可能耗时较久，请耐心等待。部署过程中，你会看到以下日志信息。如果看到提示 "Container coze-server Started"，表示 Coze Studio 服务已成功启动。
```
# 启动服务
cd docker
cp .env.example .env
docker compose --profile '*' up -d
```

4）登录访问

启动服务后，通过浏览器访问 http://localhost:8888/ 即可打开 Coze Studio。其中 8888 为后端监听端口。 至此，你已成功部署 Coze Studio，可以根据页面提示注册账号、体验 Coze Studio 的各项功能与服务。

![](https://ai.programnotes.cn/img/ai/876aa1d5ec8479eeb3e9f7c442367ac0.png)

## 2.Coze Loop部署指南

1）准备工作

在参考本文安装 CozeLoop 开源版之前，确保您的软硬件环境满足以下要求：

![](https://ai.programnotes.cn/img/ai/4171fda5beca8f878fafc8a2d9fb9a79.png)

2）安装 CozeLoop

步骤一：获取源码

执行以下命令，获取 CozeLoop 最新版本的源码。
```bash
# 克隆代码 
git 
clone
 https://github.com/coze-dev/cozeloop.git
# 进入cozeloop目录下
cd cozeloop
```

步骤二：配置模型

正式安装 CozeLoop 开源版之前，你需要准备可选的模型，否则访问 CozeLoop 开源版时将无法选择模型来启动 Prompt 调试或评测。 此处以 OpenAI 和火山方舟模型为例，演示配置模型文件的操作步骤，你可以快速配置模型以便安装和测试 CozeLoop 开源版。对于 Llama 等其他模型，你可以参考模型配置文档填写配置文件。
1. 进入目录 conf/default/app/runtime/。

1. 编辑文件 model_config.yaml，修改 api_key 和 model 字段。 以下内容表示为 CozeLoop 开源版配置火山方舟的豆包模型、OpenAI 模型。 使用以下内容覆盖原文件，然后修改其中的 api_key 和 model，将其替换为你的 OpenAI 和火山方舟模型的配置参数。

```yaml
models:
  - id: 1
    name: "doubao"
    frame: "eino"
    protocol: "ark"
    protocol_config:
      api_key: "***"  # 火山方舟 API Key，获取方式可参考 https://www.volcengine.com/docs/82379/1541594
      model: "***"    # 方舟模型 ID，可参考 https://www.volcengine.com/docs/82379/1330310
    param_config:
      param_schemas:
        - name: "temperature"
          label: "生成随机性"
          desc: "调高温度会使得模型的输出更多样性和创新性，反之，降低温度会使输出内容更加遵循指令要求但减少多样性。建议不要与 “Top p” 同时调整。"
          type: "float"
          min: "0"
          max: "1.0"
          default_val: "0.7"
        - name: "max_tokens"
          label: "最大回复长度"
          desc: "控制模型输出的 Tokens 长度上限。通常 100 Tokens 约等于 150 个中文汉字。"
          type: "int"
          min: "1"
          max: "4096"
          default_val: "2048"
        - name: "top_p"
          label: "核采样概率"
          desc: "生成时选取累计概率达 top_p 的最小 token 集合，集合外 token 被排除，平衡多样性与合理性。"
          type: "float" #
          min: "0.001"
          max: "1.0"
          default_val: "0.7"
  - id: 2
    name: "openapi"
    frame: "eino"
    protocol: "openai"
    protocol_config:
      api_key: "***"  # OpenAI API Key
      model: "***"    # OpenAI 模型 ID
    param_config:
      param_schemas:
        - name: "temperature"
          label: "生成随机性"
          desc: "调高温度会使得模型的输出更多样性和创新性，反之，降低温度会使输出内容更加遵循指令要求但减少多样性。建议不要与 “Top p” 同时调整。"
          type: "float"
          min: "0"
          max: "1.0"
          default_val: "0.7"
        - name: "max_tokens"
          label: "最大回复长度"
          desc: "控制模型输出的 Tokens 长度上限。通常 100 Tokens 约等于 150 个中文汉字。"
          type: "int"
          min: "1"
          max: "4096"
          default_val: "2048"
        - name: "top_p"
          label: "核采样概率"
          desc: "生成时选取累计概率达 top_p 的最小 token 集合，集合外 token 被排除，平衡多样性与合理性。"
          type: "float" #
          min: "0.001"
          max: "1.0"
          default_val: "0.7"
```
1. 保存文件。

步骤三：启动服务

执行以下命令，使用 Docker Compose 快速部署 CozeLoop 开源版。
```
# 启动服务，默认为开发模式
docker compose up --build
```

首次启动需要拉取镜像、构建本地镜像，可能耗时较久，请耐心等待。部署过程中，你会看到以下日志信息。如果回显信息中”提示后端构建完成“，表示 CozeLoop 已成功启动。

![](https://ai.programnotes.cn/img/ai/2f062de4dfb1bd3d1eb48e9bba2d452b.png)
- 部署 Coze Loop 开源版时，启动模式默认为开发模式。关于启动模式的详细说明，可参考启动模式。

- 如果启动过程中遇到 Docker 或 Docker Compose 相关问题，通常原因是环境配置、系统权限或网络问题，建议根据 Docker 报错查找相关解决方案。

步骤四：访问 CozeLoop 开源版

启动服务后，通过浏览器访问 http://localhost:8082 即可打开 CozeLoop 开源版。其中8082 为前端监听端口，8888 为后端监听端口。 至此，你已成功部署 CozeLoop 开源版，可以体验 CozeLoop 的各项功能与服务。

![](https://ai.programnotes.cn/img/ai/23556d04843ff83725abbc99bef96a7e.png)

