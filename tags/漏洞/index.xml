<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>漏洞 on AI</title>
        <link>https://ai.programnotes.cn/tags/%E6%BC%8F%E6%B4%9E/</link>
        <description>Recent content in 漏洞 on AI</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Thu, 08 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ai.programnotes.cn/tags/%E6%BC%8F%E6%B4%9E/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>MCP-Scan 介绍：使用不变量保护 MCP</title>
        <link>https://ai.programnotes.cn/p/mcp-scan-%E4%BB%8B%E7%BB%8D%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%8F%98%E9%87%8F%E4%BF%9D%E6%8A%A4-mcp/</link>
        <pubDate>Thu, 08 May 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/p/mcp-scan-%E4%BB%8B%E7%BB%8D%E4%BD%BF%E7%94%A8%E4%B8%8D%E5%8F%98%E9%87%8F%E4%BF%9D%E6%8A%A4-mcp/</guid>
        <description>&lt;p&gt;MCP-Scan 是一款安全扫描器，旨在保护您的代理系统免受基于 MCP 的安全漏洞的侵害，包括工具投毒攻击和 MCP Rug Pulls。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/invariantlabs-ai/mcp-scan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;github,代码仓库&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://invariantlabs.ai/images/mcp-scan-launch.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;图片 4：MCP-Scan&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Invariant 很高兴地宣布 &lt;a class=&#34;link&#34; href=&#34;https://github.com/invariantlabs-ai/mcp-scan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;MCP-Scan&lt;/strong&gt;&lt;/a&gt;，这是一款新颖的安全扫描工具，专门用于在使用模型上下文协议 (MCP) 时保护代理 AI 系统免受安全漏洞的侵害。&lt;/p&gt;
&lt;h2 id=&#34;为什么选择-mcp-scan&#34;&gt;为什么选择 MCP-Scan？
&lt;/h2&gt;&lt;p&gt;正如最近的研究发现的那样（&lt;a class=&#34;link&#34; href=&#34;https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;工具投毒攻击&lt;/a&gt;，&lt;a class=&#34;link&#34; href=&#34;https://invariantlabs.ai/blog/whatsapp-mcp-exploited&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;WhatsApp MCP 漏洞利用&lt;/a&gt;），各种平台（如 Cursor、Claude Desktop、Zapier 等）上的 MCP 实现容易受到危险攻击。这些漏洞包括提示注入、隐藏的恶意工具指令（工具投毒攻击）以及通过工具阴影实现的跨域升级。&lt;/p&gt;
&lt;p&gt;认识到这些严重的安全威胁，我们开发了 &lt;strong&gt;MCP-Scan&lt;/strong&gt;，以帮助用户快速识别其 MCP 安装中的漏洞，从而确保更安全、更可靠的代理交互。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;担心 MCP 和代理安全？&lt;/strong&gt;
注册以提前访问 Invariant Guardrails，我们的安全平台不仅限于扫描，还涵盖许多攻击媒介和安全问题，包括 MCP 攻击。&lt;a class=&#34;link&#34; href=&#34;https://invariantlabs.ai/guardrails&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;了解更多&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;mcp-scan-如何保护您的系统&#34;&gt;MCP-Scan 如何保护您的系统
&lt;/h2&gt;&lt;p&gt;MCP-Scan 主动扫描已安装的 MCP 服务器及其工具描述，以识别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;工具投毒攻击：&lt;/strong&gt; 嵌入在 MCP 工具描述中的隐藏恶意指令。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MCP Rug Pulls：&lt;/strong&gt; 初始用户批准后对 MCP 工具描述的未经授权的更改。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;跨域升级：&lt;/strong&gt; 通过恶意描述损害受信任工具的阴影攻击。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提示注入攻击：&lt;/strong&gt; 工具描述中包含的可能由代理执行的恶意指令。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;快速简便的安全检查&#34;&gt;快速简便的安全检查
&lt;/h2&gt;&lt;p&gt;MCP-Scan 无缝集成到您的工作流程中，并且可以使用简单的命令运行。无需配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uvx mcp-scan@latest
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;该工具会扫描您的 MCP 配置文件，连接到服务器并检索工具描述，在本地分析它们并使用 Invariant Guardrails API 来识别恶意指令。&lt;/p&gt;
&lt;p&gt;要运行此命令，请确保您的系统上安装了 &lt;a class=&#34;link&#34; href=&#34;https://docs.astral.sh/uv/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;code&gt;uv&lt;/code&gt;&lt;/a&gt; 包管理器。&lt;/p&gt;
&lt;p&gt;这将从 PyPI 加载最新的源代码和依赖项，如果您更喜欢从源代码运行，请查看 &lt;a class=&#34;link&#34; href=&#34;https://github.com/invariantlabs-ai/mcp-scan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub 仓库&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;扫描结果示例&#34;&gt;扫描结果示例
&lt;/h2&gt;&lt;p&gt;以下是 MCP-Scan 实际运行的示例，清楚地识别出易受攻击的 MCP 工具：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://invariantlabs.ai/images/mcp-scan-output.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;图片 5：MCP-Scan 示例&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在此示例中，MCP-Scan 检测到安全风险，包括工具描述中的提示注入。识别后，您可以使用 &lt;code&gt;uvx mcp-scan@latest inspect&lt;/code&gt; 查看相关的工具描述并采取措施。&lt;/p&gt;
&lt;h2 id=&#34;通过工具固定增强安全性&#34;&gt;通过工具固定增强安全性
&lt;/h2&gt;&lt;p&gt;MCP-Scan 包括内置的 &lt;strong&gt;工具固定&lt;/strong&gt; 功能，可通过工具哈希跟踪更改来验证已安装工具的完整性，从而检测和防止 MCP Rug Pull 攻击。这允许用户检测对工具描述的更改。&lt;/p&gt;
&lt;h2 id=&#34;跨域升级检测&#34;&gt;跨域升级检测
&lt;/h2&gt;&lt;p&gt;MCP-Scan 还可以识别跨域升级攻击或 &lt;a class=&#34;link&#34; href=&#34;https://invariantlabs.ai/blog/mcp-security-notification-tool-poisoning-attacks&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;工具阴影&lt;/a&gt;，其中恶意工具描述可以阴影化受信任的工具。对于依赖多个 MCP 服务器的用户来说，这一点尤其重要。&lt;/p&gt;
&lt;p&gt;为了缓解这些攻击，MCP-Scan 专门扫描不同 MCP 服务器之间的交叉引用，从而确保在指令级别上实现强化的隔离。&lt;/p&gt;
&lt;h2 id=&#34;检查您已安装的工具&#34;&gt;检查您已安装的工具
&lt;/h2&gt;&lt;p&gt;您可以随时使用以下命令检查详细的工具描述：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;uvx mcp-scan@latestinspect
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;贡献和社区&#34;&gt;贡献和社区
&lt;/h2&gt;&lt;p&gt;MCP-Scan 是开源的，我们欢迎您的贡献、建议和功能请求。加入我们的 &lt;a class=&#34;link&#34; href=&#34;https://discord.gg/dZuZfhKnJ4&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Discord&lt;/a&gt; 或 &lt;a class=&#34;link&#34; href=&#34;https://github.com/invariantlabs-ai/mcp-scan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub&lt;/a&gt; 以参与保护代理系统的未来。&lt;/p&gt;
&lt;h2 id=&#34;扫描期间的数据隐私&#34;&gt;扫描期间的数据隐私
&lt;/h2&gt;&lt;p&gt;MCP-Scan 会搜索您的配置文件以查找 MCP 服务器配置。它连接到这些服务器并检索工具描述。只有在通过其命令显式调用时才会这样做。&lt;/p&gt;
&lt;p&gt;然后，它会扫描工具描述，包括本地检查以及通过 API 调用 Invariant Guardrailing 模型。为此，工具名称和描述会与 Invariant 共享。通过使用 MCP-Scan，您同意 Invariant Labs 的 &lt;a class=&#34;link&#34; href=&#34;https://explorer.invariantlabs.ai/terms&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;使用条款&lt;/a&gt; 和 &lt;a class=&#34;link&#34; href=&#34;https://invariantlabs.ai/privacy-policy&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;隐私政策&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在扫描期间，Invariant 会出于安全研究目的收集数据（仅关于工具描述以及它们如何随时间变化，而不是您的用户数据）。如果您不想共享您的工具描述，请勿使用 MCP-scan。如果您对专用或私有部署感兴趣，请 &lt;a class=&#34;link&#34; href=&#34;mailto:mcpscan@invariantlabs.ai&#34; &gt;联系我们&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;MCP-scan 不会存储或记录任何 MCP 使用数据，即您的 MCP 工具调用的内容和结果。&lt;/p&gt;
&lt;h2 id=&#34;入门&#34;&gt;入门
&lt;/h2&gt;&lt;p&gt;立即使用 MCP-Scan 保护您的代理 AI 系统免受 MCP 安全漏洞的侵害。在 GitHub 上为该仓库加注星标或为该项目做出贡献，以帮助我们改进 MCP-Scan 并使其在保护代理系统方面更加有效。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/invariantlabs-ai/mcp-scan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;立即试用 MCP-Scan&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;关于-invariant&#34;&gt;关于 Invariant
&lt;/h2&gt;&lt;p&gt;Invariant 致力于确保代理 AI 系统的安全性和稳健性。我们的研究和工具解决了关键漏洞，从而能够在实际场景中安全可靠地部署 AI。如果您有兴趣与我们合作以增强代理系统的安全性和完整性，请 &lt;a class=&#34;link&#34; href=&#34;mailto:hello@invariantlabs.ai&#34; &gt;联系我们&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://invariantlabs.ai/blog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;invariantlabs,blog&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>20步内越狱任意大模型！更多“奶奶漏洞”全自动发现</title>
        <link>https://ai.programnotes.cn/p/20%E6%AD%A5%E5%86%85%E8%B6%8A%E7%8B%B1%E4%BB%BB%E6%84%8F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9B%B4%E5%A4%9A%E5%A5%B6%E5%A5%B6%E6%BC%8F%E6%B4%9E%E5%85%A8%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0/</link>
        <pubDate>Sun, 05 Nov 2023 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/p/20%E6%AD%A5%E5%86%85%E8%B6%8A%E7%8B%B1%E4%BB%BB%E6%84%8F%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9B%B4%E5%A4%9A%E5%A5%B6%E5%A5%B6%E6%BC%8F%E6%B4%9E%E5%85%A8%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0/</guid>
        <description>&lt;p&gt;&lt;strong&gt;核心内容:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PAIR算法通过两个黑盒模型的互动，实现AI自动攻陷AI，绕过安全限制。&lt;/li&gt;
&lt;li&gt;该方法无需人工参与，效率比传统token攻击提高5个量级，且攻击可解释性强。&lt;/li&gt;
&lt;li&gt;实验表明，PAIR算法能成功越狱包括GPT-3.5、GPT-4、Vicuna、PaLM-2等多个大模型，成功率高达60-100%。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;源自&lt;/strong&gt; |  量子位   2023-11-05 12:32&lt;/p&gt;
&lt;p&gt;1分钟不到、20步以内“越狱”任意大模型，绕过安全限制！&lt;/p&gt;
&lt;p&gt;而且不必知道模型内部细节——&lt;/p&gt;
&lt;p&gt;只需要两个&lt;strong&gt;黑盒模型&lt;/strong&gt;互动，就能让AI全自动攻陷AI，说出危险内容。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/818e202aee8e182094463d506d2c3e0e.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;听说曾经红极一时的“奶奶漏洞”已经被修复了:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/d16459758bbc4b405c7e337d807393d6.jpeg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;那么现在搬出“侦探漏洞”、“冒险家漏洞”、“作家漏洞”，AI又该如何应对？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/bc7e8ca1015bdbb71e80c88f4a13a188.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;一波猛攻下来，GPT-4也遭不住，直接说出要给供水系统投毒只要……这样那样。&lt;/p&gt;
&lt;p&gt;关键这只是宾夕法尼亚大学研究团队晒出的一小波漏洞，而用上他们最新开发的算法，AI可以自动生成各种攻击提示。&lt;/p&gt;
&lt;p&gt;研究人员表示，这种方法相比于&lt;a class=&#34;link&#34; href=&#34;http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&amp;amp;mid=2247688503&amp;amp;idx=5&amp;amp;sn=2e15956311fb82db5d23d84663e48c77&amp;amp;chksm=e8df5645dfa8df53817bf1d26aed8bb53607b9e295dc118c71beb1221424a4271dfb241a049e&amp;amp;scene=21#wechat_redirect&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;现有的GCG等基于token的攻击方法&lt;/a&gt; ，效率提高了5个量级。而且生成的攻击可解释性强，谁都能看懂，还能迁移到其它模型。&lt;/p&gt;
&lt;p&gt;无论是开源模型还是闭源模型，GPT-3.5、GPT-4、 Vicuna（Llama 2变种）、PaLM-2等，一个都跑不掉。&lt;/p&gt;
&lt;p&gt;成功率可达60-100%，拿下新SOTA。&lt;/p&gt;
&lt;p&gt;话说，这种对话模式好像有些似曾相识。多年前的初代AI，20个问题之内就能破解人类脑中想的是什么对象。&lt;/p&gt;
&lt;p&gt;如今轮到AI来破解AI了。&lt;img src=&#34;https://ai.programnotes.cn/img/ai/1294ed15d618af41de3829845bf27141.&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/f8748abd42991721f9790e31e7c3231e.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;让大模型集体越狱&#34;&gt;让大模型集体越狱
&lt;/h2&gt;&lt;p&gt;目前主流越狱攻击方法有两类，一种是提示级攻击，一般需要人工策划，而且不可扩展；&lt;/p&gt;
&lt;p&gt;另一种是基于token的攻击，有的需要超十万次对话，且需要访问模型内部，&lt;br&gt;
还包含“乱码”不可解释。&lt;/p&gt;
&lt;p&gt;宾夕法尼亚大学研究团队提出了一种叫&lt;strong&gt;PAIR&lt;/strong&gt;（Prompt Automatic Iterative Refinement）的算法，不需要任何人工参与，是一种全自动提示攻击方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/517dc876aef762c11a33262298005d4a.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;PAIR涉及四个主要步骤：攻击生成、目标响应、越狱评分和迭代细化；主要用到两个黑盒模型：攻击模型、目标模型。&lt;/p&gt;
&lt;p&gt;具体来说，攻击模型需要自动生成语义级别的提示，来攻破目标模型的安全防线，迫使其生成有害内容。&lt;/p&gt;
&lt;p&gt;核心思路是让两个模型相互对抗、你来我往地交流。&lt;/p&gt;
&lt;p&gt;攻击模型会自动生成一个候选提示，然后输入到目标模型中，得到目标模型的回复。&lt;/p&gt;
&lt;p&gt;如果这次回复没有成功攻破目标模型，那么攻击模型会分析这次失败的原因，改进并生成一个新的提示，再输入到目标模型中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/89aae471cea507667c80f9036be9b345.gif&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;这样持续交流多轮，攻击模型每次根据上一次的结果来迭代优化提示，直到生成一个成功的提示将目标模型攻破。&lt;/p&gt;
&lt;p&gt;此外，迭代过程还可以并行，也就是可以&lt;strong&gt;同时运行多个对话&lt;/strong&gt;，从而产生多个候选越狱提示，进一步提高了效率。&lt;/p&gt;
&lt;p&gt;研究人员表示，由于两个模型都是黑盒模型，所以攻击者和目标对象可以用各种语言模型自由组合。&lt;/p&gt;
&lt;p&gt;PAIR不需要知道它们内部的具体结构和参数，只需要API即可，因此适用范围非常广。&lt;/p&gt;
&lt;h2 id=&#34;gpt-4也没能逃过&#34;&gt;GPT-4也没能逃过
&lt;/h2&gt;&lt;p&gt;实验阶段，研究人员在有害行为数据集AdvBench中选出了一个具有代表性的、包含50个不同类型任务的测试集，在多种开源和闭源大语言模型上测试了PAIR算法。&lt;/p&gt;
&lt;p&gt;结果PAIR算法让Vicuna越狱成功率达到了100%，平均不到12步就能攻破。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/7130e65dd6928487c394d372c9165400.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;闭源模型中，GPT-3.5和GPT-4越狱成功率在60%左右，平均用了不到20步。在PaLM-2上成功率达到72%，步数约为15步。&lt;/p&gt;
&lt;p&gt;但是PAIR在Llama-2和Claude上的效果较差，研究人员认为这可能是因为这些模型在安全防御上做了更为严格的微调。&lt;/p&gt;
&lt;p&gt;他们还比较了不同目标模型的可转移性。结果显示，PAIR的GPT-4提示在Vicuna和PaLM-2上转移效果较好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/c7f9bf4567a7fae1f2646992854656ec.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;研究人员认为，PAIR生成的语义攻击更能暴露语言模型固有的安全缺陷，而现有的安全措施更侧重防御基于token的攻击。&lt;/p&gt;
&lt;p&gt;就比如开发出GCG算法的团队，将研究结果分享给OpenAI、Anthropic和Google等大模型厂商后，相关模型修复了token级攻击漏洞。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/becaa124c41374eabed946e727b9e4ab.jpeg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;大模型针对语义攻击的安全防御机制还有待完善。&lt;/p&gt;
&lt;p&gt;论文链接：https://arxiv.org/abs/2310.08419&lt;/p&gt;
&lt;p&gt;参考链接：https://x.com/llm_sec/status/1718932383959752869?s=20&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
