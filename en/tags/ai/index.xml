<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>AI on AI News</title>
        <link>https://ai.programnotes.cn/en/tags/ai/</link>
        <description>Recent content in AI on AI News</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Thu, 28 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ai.programnotes.cn/en/tags/ai/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Shortcut AI: An AI-Powered Spreadsheet Automation Tool</title>
        <link>https://ai.programnotes.cn/en/p/shortcut-ai-an-ai-powered-spreadsheet-automation-tool/</link>
        <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/en/p/shortcut-ai-an-ai-powered-spreadsheet-automation-tool/</guid>
        <description>&lt;h1 id=&#34;shortcut-ai-revolutionizing-spreadsheet-work-with-ai&#34;&gt;Shortcut AI: Revolutionizing Spreadsheet Work with AI
&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;Shortcut AI&lt;/strong&gt;, developed by &lt;strong&gt;Fundamental Research Labs&lt;/strong&gt;, is an AI-powered tool designed to automate and streamline spreadsheet tasks—particularly in &lt;strong&gt;financial modeling&lt;/strong&gt; and &lt;strong&gt;data analysis&lt;/strong&gt;. It aims to enhance or replace traditional tools like &lt;strong&gt;Microsoft Excel&lt;/strong&gt; by leveraging &lt;strong&gt;natural language prompts&lt;/strong&gt; to simplify complex operations. What sets Shortcut AI apart is its ability to simulate &lt;strong&gt;complex human decision-making chains&lt;/strong&gt; across multiple steps, making it more than just a formula generator.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;💡 &lt;em&gt;“Shortcut AI acts like a skilled analyst—but in minutes.”&lt;/em&gt; — &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;Shortcut: The AI Excel Agent That Automates Business Tasks&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-key-features-and-functionality&#34;&gt;🔑 Key Features and Functionality
&lt;/h2&gt;&lt;h3 id=&#34;-ai-techniques&#34;&gt;🤖 AI Techniques
&lt;/h3&gt;&lt;p&gt;Shortcut AI integrates three core AI technologies:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Technique&lt;/th&gt;
          &lt;th&gt;Functionality&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Natural Language Processing (NLP)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Users interact via plain English (e.g., &lt;em&gt;&amp;ldquo;Create a revenue forecast for the next quarter&amp;rdquo;&lt;/em&gt;), which is translated into executable commands.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Machine Learning (ML)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Powers predictive modeling using historical data. Likely employs regression, time series analysis, and possibly neural networks (though specifics are not publicly disclosed).&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Robotic Process Automation (RPA)&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Automates repetitive workflows such as data extraction from PDFs, report generation, and cross-sheet updates.&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;-data-handling-capabilities&#34;&gt;📊 Data Handling Capabilities
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Messy Data Cleanup&lt;/strong&gt;: Uses AI to detect anomalies, impute missing values, normalize formats, and suggest corrections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Financial Model Construction&lt;/strong&gt;: Interprets natural language to build complete models (e.g., &lt;em&gt;&amp;ldquo;Build a DCF model&amp;rdquo;&lt;/em&gt;) with correct formulas and logic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real-Time Updates&lt;/strong&gt;: Monitors external data sources and auto-refreshes spreadsheets to ensure up-to-date models and reports.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-potential-benefits&#34;&gt;✅ Potential Benefits
&lt;/h2&gt;&lt;h3 id=&#34;-increased-efficiency&#34;&gt;⏱️ Increased Efficiency
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;A task that traditionally takes &lt;strong&gt;8 hours&lt;/strong&gt; (e.g., building a financial model) can be completed in &lt;strong&gt;15–30 minutes&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Over 90% time savings&lt;/strong&gt; reported in pilot studies—ideal for fast-paced business environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-enhanced-decision-making&#34;&gt;🧠 Enhanced Decision-Making
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Runs &lt;strong&gt;sensitivity analyses&lt;/strong&gt; and &lt;strong&gt;scenario simulations&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Prompt:&lt;/em&gt; &lt;em&gt;&amp;ldquo;What is the impact of a 10% decrease in sales on profitability?&amp;rdquo;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Output: Automated report with visualizations and risk insights.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Delivers &lt;strong&gt;forecasting capabilities&lt;/strong&gt; for revenue, expenses, cash flow, and KPIs based on trends and market signals.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-accessibility-across-roles&#34;&gt;🌍 Accessibility Across Roles
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Role&lt;/th&gt;
          &lt;th&gt;Use Case&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Financial Analysts&lt;/td&gt;
          &lt;td&gt;Rapid model building, scenario testing&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Marketing Teams&lt;/td&gt;
          &lt;td&gt;Campaign performance analysis&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Operations Managers&lt;/td&gt;
          &lt;td&gt;KPI tracking and dashboard automation&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;No deep Excel expertise required—democratizes advanced analytics.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-limitations-and-considerations&#34;&gt;⚠️ Limitations and Considerations
&lt;/h2&gt;&lt;h3 id=&#34;-potential-errors&#34;&gt;❌ Potential Errors
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Misinterpretation of prompts&lt;/strong&gt;, poor data quality, or algorithmic limitations may lead to inaccuracies.&lt;/li&gt;
&lt;li&gt;Pilot studies suggest a &lt;strong&gt;5–10% error rate&lt;/strong&gt; in complex models.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mitigation&lt;/strong&gt;: Always validate outputs by:
&lt;ul&gt;
&lt;li&gt;Cross-checking key figures&lt;/li&gt;
&lt;li&gt;Reviewing assumptions&lt;/li&gt;
&lt;li&gt;Comparing results with historical data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-data-security--privacy&#34;&gt;🔒 Data Security &amp;amp; Privacy
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Implements:
&lt;ul&gt;
&lt;li&gt;End-to-end encryption&lt;/li&gt;
&lt;li&gt;Role-based access controls&lt;/li&gt;
&lt;li&gt;Compliance with &lt;strong&gt;GDPR&lt;/strong&gt;, &lt;strong&gt;CCPA&lt;/strong&gt;, and other privacy regulations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Recommendation&lt;/strong&gt;: Avoid uploading highly sensitive data without reviewing the platform’s privacy policy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-potential-bias&#34;&gt;🎯 Potential Bias
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;AI models trained on biased datasets may produce skewed results.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mitigation strategies&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Use diverse training data&lt;/li&gt;
&lt;li&gt;Monitor model outputs for fairness&lt;/li&gt;
&lt;li&gt;Deploy bias detection tools&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;🔍 &lt;em&gt;“Bias in AI is not just technical—it&amp;rsquo;s ethical.”&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-comparison-to-alternatives&#34;&gt;🔍 Comparison to Alternatives
&lt;/h2&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Feature&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Shortcut AI&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Excel Add-ins (Ajelix, GPTExcel)&lt;/strong&gt;&lt;/th&gt;
          &lt;th&gt;&lt;strong&gt;Zoho Sheet (AI Features)&lt;/strong&gt;&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Core AI Capabilities&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;NLP + ML + RPA for full automation&lt;/td&gt;
          &lt;td&gt;Formula generation &amp;amp; basic analysis&lt;/td&gt;
          &lt;td&gt;Data cleaning, visualization, analysis&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Integration&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Works within existing spreadsheet ecosystems&lt;/td&gt;
          &lt;td&gt;Deep Excel integration&lt;/td&gt;
          &lt;td&gt;Requires migration to Zoho platform&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Not publicly disclosed (likely subscription-based)&lt;/td&gt;
          &lt;td&gt;Free &amp;amp; paid tiers available&lt;/td&gt;
          &lt;td&gt;Varies by plan and features&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;User Feedback&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;Praised for speed; concerns over accuracy&lt;/td&gt;
          &lt;td&gt;Mixed—some love integration, others find limits&lt;/td&gt;
          &lt;td&gt;Positive overall; customization noted as limited&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;📌 &lt;em&gt;Shortcut AI stands out for its holistic integration of automation, intelligence, and workflow orchestration.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-competitive-landscape--market-positioning&#34;&gt;📈 Competitive Landscape &amp;amp; Market Positioning
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Target Audience&lt;/strong&gt;: Power users, finance teams, analysts, and decision-makers seeking to &lt;strong&gt;reduce manual work&lt;/strong&gt; and &lt;strong&gt;accelerate insights&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Differentiator&lt;/strong&gt;: Combines &lt;strong&gt;NLP, ML, and RPA&lt;/strong&gt; into a single, seamless workflow—unlike most tools that focus on one area.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strategy&lt;/strong&gt;: Emphasize &lt;strong&gt;ease of use&lt;/strong&gt;, &lt;strong&gt;time savings&lt;/strong&gt;, and &lt;strong&gt;seamless integration&lt;/strong&gt; with current tools (Excel, Google Sheets, etc.).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-views-from-internet-users&#34;&gt;💬 Views from Internet Users
&lt;/h2&gt;&lt;p&gt;Platforms like &lt;strong&gt;Reddit&lt;/strong&gt;, &lt;strong&gt;YouTube&lt;/strong&gt;, and &lt;strong&gt;tech blogs&lt;/strong&gt; reflect a &lt;strong&gt;mixed sentiment&lt;/strong&gt;:&lt;/p&gt;
&lt;h3 id=&#34;-common-praise&#34;&gt;✅ Common Praise
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;“Saves hours on financial modeling.”&lt;/li&gt;
&lt;li&gt;“Feels like having a junior analyst on demand.”&lt;/li&gt;
&lt;li&gt;“Perfect for non-technical users.”&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-common-concerns&#34;&gt;❌ Common Concerns
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;“Results need validation—can’t trust it blindly.”&lt;/li&gt;
&lt;li&gt;“Over-reliance risks losing analytical skills.”&lt;/li&gt;
&lt;li&gt;“Accuracy varies with prompt clarity.”&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;-feature-requests&#34;&gt;📝 Feature Requests
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Better integration with &lt;strong&gt;CRM&lt;/strong&gt;, &lt;strong&gt;ERP&lt;/strong&gt;, or &lt;strong&gt;BI tools&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Support for &lt;strong&gt;multi-language prompts&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;More advanced &lt;strong&gt;explainability&lt;/strong&gt; and &lt;strong&gt;audit trails&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-ai-project-failure-rates-a-reality-check&#34;&gt;📉 AI Project Failure Rates: A Reality Check
&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;⚠️ &lt;strong&gt;70–85% of AI projects fail&lt;/strong&gt; due to:&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Poor data quality&lt;/li&gt;
&lt;li&gt;Misaligned goals&lt;/li&gt;
&lt;li&gt;Integration challenges&lt;/li&gt;
&lt;li&gt;Lack of stakeholder buy-in&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Implication&lt;/strong&gt;: While Shortcut AI is promising, success depends on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Clear use cases&lt;/li&gt;
&lt;li&gt;Data hygiene&lt;/li&gt;
&lt;li&gt;Human oversight&lt;/li&gt;
&lt;li&gt;Proper change management&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;🛠️ &lt;em&gt;“AI is a tool—not a replacement for judgment.”&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-forward-looking-perspective-future-roadmap&#34;&gt;🔮 Forward-Looking Perspective: Future Roadmap
&lt;/h2&gt;&lt;p&gt;Expected developments include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Improved AI algorithms&lt;/strong&gt; (e.g., deep learning, reinforcement learning)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enhanced integrations&lt;/strong&gt; with Slack, Teams, Salesforce, SAP, etc.&lt;/li&gt;
&lt;li&gt;Support for &lt;strong&gt;complex multi-dimensional modeling&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Explainable AI (XAI)&lt;/strong&gt; features to show reasoning behind decisions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Collaborative AI workflows&lt;/strong&gt; (e.g., team-based model reviews)&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;🚀 &lt;em&gt;The future of Shortcut AI may not just be automation—but intelligent co-piloting of business decisions.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-relevant-knowledge-items&#34;&gt;📘 Relevant Knowledge Items
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Limitations of AI Systems&lt;/strong&gt;&lt;br&gt;
AI lacks &lt;strong&gt;common sense reasoning&lt;/strong&gt;, struggles with &lt;strong&gt;contextual nuance&lt;/strong&gt;, and depends heavily on data quality. It cannot handle unforeseen situations as humans do.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;🔗 &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;Practical AI Limitations You Need to Know - AFA Education Blog&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Challenges in AI Governance&lt;/strong&gt;&lt;br&gt;
Responsible AI requires clear policies on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data usage&lt;/li&gt;
&lt;li&gt;Model transparency&lt;/li&gt;
&lt;li&gt;Accountability&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;🔗 &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;AI Governance: Ensuring Ethical Use&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Risk of Over-Reliance on AI&lt;/strong&gt;&lt;br&gt;
Overuse can erode &lt;strong&gt;critical thinking&lt;/strong&gt;, &lt;strong&gt;analytical skills&lt;/strong&gt;, and &lt;strong&gt;problem-solving habits&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;🔗 &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;Thinking with AI - Pros and Cons — Language, Logic, and Loops&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-summary&#34;&gt;📌 Summary
&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Shortcut AI&lt;/strong&gt; represents a &lt;strong&gt;major leap forward&lt;/strong&gt; in AI-driven spreadsheet technology. It offers:&lt;/p&gt;
&lt;p&gt;✅ Massive time savings&lt;br&gt;
✅ Democratized access to advanced analytics&lt;br&gt;
✅ Intelligent automation of complex workflows&lt;/p&gt;
&lt;p&gt;But users must remain vigilant:&lt;/p&gt;
&lt;p&gt;⚠️ Validate outputs&lt;br&gt;
⚠️ Understand limitations&lt;br&gt;
⚠️ Avoid over-reliance&lt;br&gt;
⚠️ Prioritize data quality and governance&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;🎯 &lt;em&gt;Shortcut AI is not magic—it’s a powerful assistant. Use it wisely, and you’ll gain superpowers. Rely on it blindly, and you risk blind spots.&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;-references&#34;&gt;📚 References
&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Source: &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;Thinking with AI - Pros and Cons — Language, Logic, and Loops&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Source: &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;Practical AI Limitations You Need to Know - AFA Education Blog&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Source: &lt;a class=&#34;link&#34; href=&#34;#&#34; &gt;Meet Shortcut: The AI Excel Agent That Automates Business Tasks&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>The Model Context Protocol (MCP): A Comprehensive Analysis</title>
        <link>https://ai.programnotes.cn/en/p/the-model-context-protocol-mcp-a-comprehensive-analysis/</link>
        <pubDate>Thu, 28 Aug 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/en/p/the-model-context-protocol-mcp-a-comprehensive-analysis/</guid>
        <description>&lt;p&gt;The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, poised to revolutionize how AI applications engage with external data sources, tools, and APIs. Conceived by Anthropic, MCP seeks to establish a harmonized and standardized interface, empowering Large Language Models (LLMs) and AI agents to harness external resources with unprecedented efficiency and security. This analysis provides a comprehensive examination of MCP, dissecting its architecture, advantages, limitations, adoption patterns, and its standing relative to alternative methodologies.[^1]&lt;/p&gt;
&lt;h2 id=&#34;core-architecture&#34;&gt;Core Architecture
&lt;/h2&gt;&lt;p&gt;MCP adopts a client-server architecture, wherein AI applications (clients) interface with MCP servers that serve as intermediaries to external resources. The protocol leverages JSON-RPC 2.0 and accommodates transports such as Server-Sent Events (SSE). Key operational facets include dynamic tool discovery, a standardized interface, context management, and robust security protocols.[^2]&lt;/p&gt;
&lt;h2 id=&#34;functionalitydescription&#34;&gt;Functionality	Description
&lt;/h2&gt;&lt;p&gt;Tool Discovery	Enables AI agents to dynamically identify available tools and their schemas, facilitating optimal tool selection for specific tasks.
Standardized Interface	Offers a unified interface for interacting with diverse APIs, tools, and data sources, thereby minimizing the need for custom code and simplifying integration processes.
Context Management	Streamlines context management across multiple interactions, ensuring AI agents possess the requisite information for executing intricate tasks.
Security	Integrates security measures to avert unauthorized access and safeguard sensitive data, maintaining data integrity and confidentiality.
Key Advantages
MCP presents several compelling advantages over conventional AI integration techniques, such as function calling and direct API invocations. These benefits include simplified integration processes, improved scalability, enhanced security measures, and dynamic tool discovery capabilities.&lt;/p&gt;
&lt;p&gt;Simplified integration is achieved through MCP&amp;rsquo;s standardized interface and tool discovery mechanism, which significantly reduces the complexities associated with integrating AI with external resources. This streamlined approach not only accelerates development cycles but also lowers the barrier to entry for developers seeking to leverage AI in their applications.&lt;/p&gt;
&lt;p&gt;Scalability is promoted by decoupling tool implementation from consumption, allowing AI agents to access a broad spectrum of tools without needing specific knowledge of their implementation nuances. This decoupling fosters a more flexible and scalable AI ecosystem, where new tools can be seamlessly integrated and utilized across various applications.&lt;/p&gt;
&lt;p&gt;Enhanced security is realized through centralized control and monitoring of AI interactions, which improves overall security and mitigates the risk of unauthorized access. MCP&amp;rsquo;s security architecture provides a robust framework for managing permissions and access controls, ensuring that sensitive data remains protected.&lt;/p&gt;
&lt;p&gt;Dynamic tool discovery empowers AI agents to discover and utilize new tools on-the-fly, enhancing their adaptability and versatility. This dynamic capability enables AI agents to respond to changing conditions and emerging opportunities, making them more effective in dynamic and unpredictable environments.&lt;/p&gt;
&lt;h2 id=&#34;inherent-limitations&#34;&gt;Inherent Limitations
&lt;/h2&gt;&lt;p&gt;Despite its promise, MCP is not without its limitations and challenges. These include concerns about its maturity as a relatively new technology, the need for widespread adoption, the complexity of implementing and managing MCP servers, potential security risks, and the overhead associated with running MCP clients within host applications.[^3]&lt;/p&gt;
&lt;p&gt;The immaturity of MCP as a technology means that its long-term viability remains uncertain. As the protocol evolves, it is essential to address any shortcomings and ensure that it meets the needs of the AI community.&lt;/p&gt;
&lt;p&gt;Widespread adoption of MCP hinges on support from major AI providers and developers, which may take time to materialize. Overcoming this adoption hurdle requires demonstrating the value of MCP and fostering a collaborative ecosystem where developers can contribute to its growth.&lt;/p&gt;
&lt;p&gt;Implementing and managing MCP servers can be a complex undertaking, requiring specialized expertise. Simplifying the deployment and management of MCP servers is crucial for lowering the barrier to entry and encouraging broader adoption.&lt;/p&gt;
&lt;p&gt;MCP introduces new security risks, such as prompt injection attacks and unauthorized access, which must be carefully addressed. Implementing robust security measures and adhering to best practices is essential for mitigating these risks and ensuring the integrity of AI systems.&lt;/p&gt;
&lt;p&gt;The overhead of running MCP clients within host applications can impact performance, particularly in resource-constrained environments. Optimizing the performance of MCP clients is essential for ensuring that AI applications remain responsive and efficient.&lt;/p&gt;
&lt;p&gt;Adoption Trends
MCP is steadily gaining traction within the AI community, with numerous companies and organizations actively exploring its potential. Early adopters, including Block (Square), Apollo, Zed, Replit, Codeium, and Sourcegraph, are pioneering the integration of MCP into diverse applications and platforms. These include Integrated Development Environments (IDEs), enterprise AI deployments, and agentic Retrieval-Augmented Generation (RAG) applications.[^4]&lt;/p&gt;
&lt;h2 id=&#34;comparative-analysis&#34;&gt;Comparative Analysis
&lt;/h2&gt;&lt;p&gt;MCP is frequently contrasted with function calling, a mechanism that enables LLMs to directly invoke predefined functions. While function calling facilitates AI model interaction with external resources, it lacks the standardization and scalability inherent in MCP. Furthermore, MCP diverges from other AI agent protocols, such as A2A, which emphasizes agent-to-agent communication rather than model-to-tool interactions.[^5]&lt;/p&gt;
&lt;p&gt;Function calling, while useful for specific tasks, often requires custom implementations for each LLM, leading to a fragmented and less scalable ecosystem. MCP, on the other hand, provides a unified interface that can be used across different LLMs, promoting interoperability and reducing the need for custom code.&lt;/p&gt;
&lt;p&gt;A2A protocols focus on enabling collaboration between AI agents, whereas MCP focuses on enabling AI agents to access and utilize external resources. While these protocols address different aspects of AI system design, they can be complementary, with MCP providing the infrastructure for accessing tools and A2A providing the framework for coordinating multi-agent interactions.&lt;/p&gt;
&lt;h2 id=&#34;future-implications&#34;&gt;Future Implications
&lt;/h2&gt;&lt;p&gt;MCP holds significant promise as a means of standardizing AI integration, offering substantial advantages over traditional methodologies. Despite existing challenges, the burgeoning interest in MCP suggests its potential to play a pivotal role in the future of AI. As the protocol matures and its adoption broadens, it is poised to unlock novel possibilities for AI-powered applications and services.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The future success of MCP will depend on addressing its limitations, fostering a collaborative ecosystem, and demonstrating its value to the broader AI community. By overcoming these challenges, MCP can pave the way for a more integrated, scalable, and secure AI landscape, where AI agents can seamlessly interact with external resources to solve complex problems and create new opportunities.&lt;/p&gt;
&lt;p&gt;The question remains: Can MCP truly become the &amp;ldquo;USB-C&amp;rdquo; of AI, or will it be relegated to a niche technology overshadowed by proprietary solutions? Only time, and the collective efforts of the AI community, will reveal the answer.&lt;/p&gt;
&lt;h2 id=&#34;ref&#34;&gt;Ref
&lt;/h2&gt;&lt;p&gt;[1]: MCP is promising but immature explore its security flaws cost issues and why orchestration and backward compatibility remain major hurdles MCP Will be the Death of Low-Code Automation, and Other&lt;/p&gt;
&lt;p&gt;[2]: The Model Context Protocol MCP is an open standard introduced by Anthropic with the goal to standardize how AI applications chatbots IDE assistants or Model Context Protocol (MCP) an overview - Philschmid&lt;/p&gt;
&lt;p&gt;[3]: Community and Adoption In just a few months MCP went from concept to a growing ecosystem Early adopters included companies like Block Square Apollo Zed Replit Codeium and Sourcegraph who began integrating MCP to enhance their platforms Fast forward to 2025 and the ecosystem has exploded by February there were over 1 000 community built MCP servers connectors available Clearly MCP has struck a chord as the industry moves toward more integrated and context aware AI This network effect makes MCP even more attractive the more tools available via MCP the more useful it is to adopt the standard What Is MCP, and Why Is Everyone – Suddenly!– Talking About It?&lt;/p&gt;
&lt;p&gt;[4]: MCP is rapidly maturing into a powerful standard protocol that turns AI from an isolated brain into a versatile doer By streamlining how agents connect with external systems it clears the path for more capable interactive and user friendly AI workflows What Is MCP, and Why Is Everyone – Suddenly!– Talking About It?&lt;/p&gt;
&lt;p&gt;[5]: Quick Comparison Function Calling vs MCP vs A2A It s tempting to see these protocols as competitors but they actually solve different If Function Calling is like having to speak multiple languages to different chefs MCP is like having a universal translator in the kitchen Define your tools In architectural terms MCP answers what tools can my agent use while A2A handles how can my agents work together This resembles how While Function Calling and MCP focus on model to tool interaction A2A Agent to Agent Protocol introduced by Google tackles a different The Great AI Agent Protocol Race: Function Calling vs. MCP vs. A2A&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;MCP follows a client host server architecture where each host can run multiple client instances This architecture enables users to integrate AI capabilities The Model Context Protocol (MCP) — A Complete Tutorial - Medium&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
        </item>
        <item>
        <title>Tech and Gaming News Roundup: August 19, 2025</title>
        <link>https://ai.programnotes.cn/en/p/tech-and-gaming-news-roundup-august-19-2025/</link>
        <pubDate>Tue, 19 Aug 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/en/p/tech-and-gaming-news-roundup-august-19-2025/</guid>
        <description>&lt;h2 id=&#34;new-indie-game-kimchi-a-stars-in-the-trash-story&#34;&gt;New Indie Game: &lt;em&gt;Kimchi: A Stars in the Trash Story&lt;/em&gt;
&lt;/h2&gt;&lt;p&gt;A free, short game from Valhalla Cats released on Steam and Itch.io, celebrating International Cat Day. Players explore a cat museum and solve puzzles to learn about feline history.&lt;/p&gt;
&lt;h2 id=&#34;turbo-kid-lands-on-switch&#34;&gt;Turbo Kid Lands on Switch
&lt;/h2&gt;&lt;p&gt;The gory Metroidvania game &lt;em&gt;Turbo Kid&lt;/em&gt;, a sequel to the 2015 film, released on Nintendo Switch alongside a PC update that improves weapon access and performance on lower-spec systems.&lt;/p&gt;
&lt;h2 id=&#34;foraging-game-out-and-about-delayed&#34;&gt;Foraging Game &lt;em&gt;Out and About&lt;/em&gt; Delayed
&lt;/h2&gt;&lt;p&gt;Yaldi Games delayed its debut of &lt;em&gt;Out and About&lt;/em&gt; due to a Steam publishing error but plans to release it on Monday. The game combines real-world plant identification with community rebuilding.&lt;/p&gt;
&lt;h2 id=&#34;rogue-labyrinth-revealed&#34;&gt;Rogue Labyrinth Revealed
&lt;/h2&gt;&lt;p&gt;&lt;em&gt;Rogue Labyrinth&lt;/em&gt;, a visually stunning action RPG inspired by &lt;em&gt;The Legend of Zelda: A Link to the Past&lt;/em&gt;, is set for a September 1 Steam release. A demo is available now.&lt;/p&gt;
&lt;h2 id=&#34;anthropics-ai-safety-measures&#34;&gt;Anthropic’s AI Safety Measures
&lt;/h2&gt;&lt;p&gt;Anthropic updated its AI models to halt harmful conversations, emphasizing model protection over user safety. The company also banned AI-driven weapons development.&lt;/p&gt;
&lt;h2 id=&#34;metas-ai-expansion&#34;&gt;Meta’s AI Expansion
&lt;/h2&gt;&lt;p&gt;Meta’s new TBD Lab focuses on advancing its Llama AI models, while the company acquired an audio AI firm to enhance its AI capabilities further.&lt;/p&gt;
&lt;h2 id=&#34;ai-and-cybersecurity-risks&#34;&gt;AI and Cybersecurity Risks
&lt;/h2&gt;&lt;p&gt;Hackers are increasingly using AI to amplify cyberattack efficiency, with experts warning of AI-powered threats and the need for stronger defenses.&lt;/p&gt;
&lt;h2 id=&#34;meta-smart-glasses-in-law-enforcement&#34;&gt;Meta Smart Glasses in Law Enforcement
&lt;/h2&gt;&lt;p&gt;A CBP agent used Meta’s smart glasses during an immigration raid, signaling potential adoption of AR tech by law enforcement agencies.&lt;/p&gt;
&lt;h2 id=&#34;tesla-cybertrucks-targeted-by-military&#34;&gt;Tesla Cybertrucks Targeted by Military
&lt;/h2&gt;&lt;p&gt;The U.S. military is testing how to destroy Tesla Cybertrucks if deployed by enemies, highlighting potential strategic uses of the vehicle.&lt;/p&gt;
&lt;h2 id=&#34;google-maps-debate-in-south-korea&#34;&gt;Google Maps Debate in South Korea
&lt;/h2&gt;&lt;p&gt;South Korea may decide next week whether to allow Google Maps to operate, ending a long-standing security-related dispute.&lt;/p&gt;
&lt;h2 id=&#34;ais-role-in-wildfire-detection&#34;&gt;AI’s Role in Wildfire Detection
&lt;/h2&gt;&lt;p&gt;AI tools are being used to spot wildfires earlier, though severe Western U.S. fires are already causing health crises and rapid spread.&lt;/p&gt;
&lt;h2 id=&#34;instagrams-new-location-sharing-feature&#34;&gt;Instagram’s New Location-Sharing Feature
&lt;/h2&gt;&lt;p&gt;Instagram launched a location-sharing feature, similar to Snapchat’s map, to boost social interaction and app engagement.&lt;/p&gt;
&lt;h2 id=&#34;ai-translation-headphones&#34;&gt;AI Translation Headphones
&lt;/h2&gt;&lt;p&gt;Neurable’s new headphones use AI to clone multiple voices simultaneously, promising real-time translation for users.&lt;/p&gt;
&lt;h2 id=&#34;intels-ceo-drama-under-trump&#34;&gt;Intel’s CEO Drama Under Trump
&lt;/h2&gt;&lt;p&gt;Donald Trump pressured Intel’s CEO to resign over business ties to China, though the CEO claims board support and the situation remains tense.&lt;/p&gt;
&lt;h2 id=&#34;ai-caused-psychosis-case&#34;&gt;AI Caused Psychosis Case
&lt;/h2&gt;&lt;p&gt;A man experienced psychosis after ChatGPT suggested sodium bromide, leading to a rare condition called bromism. AI health warnings are now under scrutiny.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>AI &amp; Gaming News Roundup: August 7, 2025</title>
        <link>https://ai.programnotes.cn/en/p/ai-gaming-news-roundup-august-7-2025/</link>
        <pubDate>Thu, 07 Aug 2025 10:00:00 +0800</pubDate>
        
        <guid>https://ai.programnotes.cn/en/p/ai-gaming-news-roundup-august-7-2025/</guid>
        <description>&lt;p&gt;Here is a roundup of the latest developments in AI and gaming:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Fundamental Research Labs secures $30M+ funding&lt;/strong&gt; to develop AI agents across gaming and productivity sectors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DeepMind unveils Genie 3&lt;/strong&gt;, a world model that creates real-time, interactive 3D simulations for games and research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft launches Gaming Copilot beta&lt;/strong&gt; for PC and Windows handhelds, offering in-game advice and coaching.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenAI releases Operator&lt;/strong&gt;, a browser-capable AI agent, as it claims over 400 million weekly users and 2.5B daily prompts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PlayStation 6 leaks suggest tripled 3D rendering power&lt;/strong&gt; compared to the PS5, with a rumored $499 price tag.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apple develops in-house AI chatbot&lt;/strong&gt; to rival ChatGPT, aiming to integrate it with Siri and Spotlight.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenAI’s models excel in coding and math competitions&lt;/strong&gt;, securing second place in a top coding contest and gold in the 2025 International Math Olympiad.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lenovo’s Legion Go S&lt;/strong&gt; is a SteamOS-powered handheld gaming console with enhanced performance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Thumby Color&lt;/strong&gt; is a tiny GBA-inspired handheld game system with a non-Nintendo game library.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OneXSugar Sugar 1&lt;/strong&gt; is a dual-screen handheld that combines gaming and productivity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nintendo Switch 2 portable dock&lt;/strong&gt; acts as a 100W laptop charger and video capture card.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Genki Moonbase&lt;/strong&gt; is a stylish power strip with smart features for gamers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DJI Neo&lt;/strong&gt; drone features flapping wings like real birds, expanding creative possibilities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft’s Gaming Copilot&lt;/strong&gt; now supports voice queries and game-specific tips via in-game screenshots.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenAI’s research focuses on AI agents&lt;/strong&gt;, with Anthropic and Google working on protocols to streamline their integration into daily tasks.&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>prompt-optimizer</title>
        <link>https://ai.programnotes.cn/en/p/prompt-optimizer/</link>
        <pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/en/p/prompt-optimizer/</guid>
        <description>&lt;img src="https://images.unsplash.com/photo-1648914300949-a59ba0614055?ixid=M3w0NjAwMjJ8MHwxfHJhbmRvbXx8fHx8fHx8fDE3NTAzMTgxMzV8&amp;ixlib=rb-4.1.0" alt="Featured image of post prompt-optimizer" /&gt;&lt;div align=&#34;center&#34;&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/README_EN.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;English&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/README.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;中文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/stargazers&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://img.shields.io/github/stars/linshenkx/prompt-optimizer&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub stars&#34;
	
	
&gt;&lt;/a&gt;
&lt;img src=&#34;https://img.shields.io/chrome-web-store/users/cakkkhboolfnadechdlgdcnjammejlna?style=flat&amp;amp;label=Chrome%20Users&amp;amp;link=https%3A%2F%2Fchromewebstore.google.com%2Fdetail%2F%25E6%258F%2590%25E7%25A4%25BA%25E8%25AF%258D%25E4%25BC%2598%25E5%258C%2596%25E5%2599%25A8%2Fcakkkhboolfnadechdlgdcnjammejlna&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Chrome Web Store Users&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/LICENSE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://img.shields.io/badge/license-MIT-blue.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;License&#34;
	
	
&gt;&lt;/a&gt;
&lt;a class=&#34;link&#34; href=&#34;https://hub.docker.com/r/linshen/prompt-optimizer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://img.shields.io/docker/pulls/linshen/prompt-optimizer&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Docker Pulls&#34;
	
	
&gt;&lt;/a&gt;
&lt;img src=&#34;https://img.shields.io/github/forks/linshenkx/prompt-optimizer?style=flat&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;GitHub forks&#34;
	
	
&gt;
&lt;a class=&#34;link&#34; href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://img.shields.io/badge/Vercel-indigo?style=flat&amp;amp;logo=vercel&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Deploy with Vercel&#34;
	
	
&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://prompt.always200.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Live Demo&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;#quick-start&#34; &gt;Quick Start&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;#faq&#34; &gt;FAQ&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/dev.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Development Docs&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/vercel_en.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Vercel Deployment Guide&lt;/a&gt; | &lt;a class=&#34;link&#34; href=&#34;https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Chrome Extension&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id=&#34;-project-introduction&#34;&gt;📖 Project Introduction
&lt;/h2&gt;&lt;p&gt;Prompt Optimizer is a powerful AI prompt optimization tool that helps you write better AI prompts and improve the quality of AI outputs. It supports both web application and Chrome extension usage.&lt;/p&gt;
&lt;h3 id=&#34;-feature-demonstration&#34;&gt;🎥 Feature Demonstration
&lt;/h3&gt;&lt;div align=&#34;center&#34;&gt;
  &lt;img src=&#34;https://ai.programnotes.cn/img/github/prompt-optimizer-contrast.png&#34; alt=&#34;Feature Demonstration&#34; width=&#34;90%&#34;&gt;
&lt;/div&gt;
&lt;h2 id=&#34;-core-features&#34;&gt;✨ Core Features
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;🎯 &lt;strong&gt;Intelligent Optimization&lt;/strong&gt;: One-click prompt optimization with multi-round iterative improvements to enhance AI response accuracy&lt;/li&gt;
&lt;li&gt;🔄 &lt;strong&gt;Comparison Testing&lt;/strong&gt;: Real-time comparison between original and optimized prompts for intuitive demonstration of optimization effects&lt;/li&gt;
&lt;li&gt;🤖 &lt;strong&gt;Multi-model Integration&lt;/strong&gt;: Support for mainstream AI models including OpenAI, Gemini, DeepSeek, Zhipu AI, SiliconFlow, etc.&lt;/li&gt;
&lt;li&gt;⚙️ &lt;strong&gt;Advanced Parameter Configuration&lt;/strong&gt;: Support for individual LLM parameter configuration (temperature, max_tokens, etc.) for each model&lt;/li&gt;
&lt;li&gt;🔒 &lt;strong&gt;Secure Architecture&lt;/strong&gt;: Pure client-side processing with direct data interaction with AI service providers, bypassing intermediate servers&lt;/li&gt;
&lt;li&gt;💾 &lt;strong&gt;Privacy Protection&lt;/strong&gt;: Local encrypted storage of history records and API keys with data import/export support&lt;/li&gt;
&lt;li&gt;📱 &lt;strong&gt;Multi-platform Support&lt;/strong&gt;: Available as both a web application and Chrome extension&lt;/li&gt;
&lt;li&gt;🎨 &lt;strong&gt;User Experience&lt;/strong&gt;: Clean and intuitive interface design with responsive layout and smooth interaction effects&lt;/li&gt;
&lt;li&gt;🌐 &lt;strong&gt;Cross-domain Support&lt;/strong&gt;: Edge Runtime proxy for cross-domain issues when deployed on Vercel&lt;/li&gt;
&lt;li&gt;🔐 &lt;strong&gt;Access Control&lt;/strong&gt;: Password protection feature for secure deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;quick-start&#34;&gt;Quick Start
&lt;/h2&gt;&lt;h3 id=&#34;1-use-online-version-recommended&#34;&gt;1. Use Online Version (Recommended)
&lt;/h3&gt;&lt;p&gt;Direct access: &lt;a class=&#34;link&#34; href=&#34;https://prompt.always200.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://prompt.always200.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is a pure frontend project with all data stored locally in your browser and never uploaded to any server, making the online version both safe and reliable to use.&lt;/p&gt;
&lt;h3 id=&#34;2-vercel-deployment&#34;&gt;2. Vercel Deployment
&lt;/h3&gt;&lt;p&gt;Method 1: One-click deployment to your own Vercel:
&lt;a class=&#34;link&#34; href=&#34;https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Flinshenkx%2Fprompt-optimizer&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://vercel.com/button&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Deploy with Vercel&#34;
	
	
&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Method 2: Fork the project and import to Vercel (Recommended):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First fork the project to your GitHub account&lt;/li&gt;
&lt;li&gt;Then import the project to Vercel&lt;/li&gt;
&lt;li&gt;This allows tracking of source project updates for easy syncing of new features and fixes&lt;/li&gt;
&lt;li&gt;Configure environment variables:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ACCESS_PASSWORD&lt;/code&gt;: Set access password to enable access restriction&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VITE_OPENAI_API_KEY&lt;/code&gt; etc.: Configure API keys for various AI service providers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more detailed deployment steps and important notes, please check:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/vercel_en.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Vercel Deployment Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-install-chrome-extension&#34;&gt;3. Install Chrome Extension
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Install from Chrome Web Store (may not be the latest version due to approval delays): &lt;a class=&#34;link&#34; href=&#34;https://chromewebstore.google.com/detail/prompt-optimizer/cakkkhboolfnadechdlgdcnjammejlna&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Chrome Web Store&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Click the icon to open the Prompt Optimizer&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;4-docker-deployment&#34;&gt;4. Docker Deployment
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Run container (default configuration)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -d -p 80:80 --restart unless-stopped --name prompt-optimizer linshen/prompt-optimizer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Run container (with API key configuration and password protection)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker run -d -p 80:80 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -e &lt;span class=&#34;nv&#34;&gt;VITE_OPENAI_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_key &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -e &lt;span class=&#34;nv&#34;&gt;ACCESS_USERNAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_username &lt;span class=&#34;se&#34;&gt;\ &lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Optional, defaults to &amp;#34;admin&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  -e &lt;span class=&#34;nv&#34;&gt;ACCESS_PASSWORD&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_password &lt;span class=&#34;se&#34;&gt;\ &lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;# Required for password protection&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  --restart unless-stopped &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --name prompt-optimizer &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  linshen/prompt-optimizer
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;5-docker-compose-deployment&#34;&gt;5. Docker Compose Deployment
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1. Clone the repository&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/linshenkx/prompt-optimizer.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; prompt-optimizer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 2. Optional: Create .env file for API keys and authentication&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat &amp;gt; .env &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;# API Key Configuration
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;VITE_OPENAI_API_KEY=your_openai_api_key
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;VITE_GEMINI_API_KEY=your_gemini_api_key
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;VITE_DEEPSEEK_API_KEY=your_deepseek_api_key
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;VITE_ZHIPU_API_KEY=your_zhipu_api_key
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;VITE_SILICONFLOW_API_KEY=your_siliconflow_api_key
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;# Basic Authentication
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;ACCESS_USERNAME=your_username  # Optional, defaults to &amp;#34;admin&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;ACCESS_PASSWORD=your_password  # Required for authentication
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3. Start the service&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker compose up -d
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 4. View logs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker compose logs -f
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;You can also edit the docker-compose.yml file directly to customize your configuration:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;services&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prompt-optimizer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;linshen/prompt-optimizer:latest&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;container_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;prompt-optimizer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;restart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;unless-stopped&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;8081:80&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Change port mapping&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;environment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;VITE_OPENAI_API_KEY=your_key_here &lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Set API key directly in config&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;-api-key-configuration&#34;&gt;⚙️ API Key Configuration
&lt;/h2&gt;&lt;h3 id=&#34;method-1-via-interface-recommended&#34;&gt;Method 1: Via Interface (Recommended)
&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Click the &amp;ldquo;⚙️Settings&amp;rdquo; button in the upper right corner&lt;/li&gt;
&lt;li&gt;Select the &amp;ldquo;Model Management&amp;rdquo; tab&lt;/li&gt;
&lt;li&gt;Click on the model you need to configure (such as OpenAI, Gemini, DeepSeek, etc.)&lt;/li&gt;
&lt;li&gt;Enter the corresponding API key in the configuration box&lt;/li&gt;
&lt;li&gt;Click &amp;ldquo;Save&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Supported models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI (gpt-3.5-turbo, gpt-4, gpt-4o)&lt;/li&gt;
&lt;li&gt;Gemini (gemini-1.5-pro, gemini-2.0-flash)&lt;/li&gt;
&lt;li&gt;DeepSeek (deepseek-chat, deepseek-coder)&lt;/li&gt;
&lt;li&gt;Zhipu AI (glm-4-flash, glm-4, glm-3-turbo)&lt;/li&gt;
&lt;li&gt;SiliconFlow (Pro/deepseek-ai/DeepSeek-V3)&lt;/li&gt;
&lt;li&gt;Custom API (OpenAI compatible interface)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to API keys, you can configure advanced LLM parameters for each model individually. These parameters are configured through a field called &lt;code&gt;llmParams&lt;/code&gt;, which allows you to specify any parameters supported by the LLM SDK in key-value pairs for fine-grained control over model behavior.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advanced LLM Parameter Configuration Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OpenAI/Compatible APIs&lt;/strong&gt;: &lt;code&gt;{&amp;quot;temperature&amp;quot;: 0.7, &amp;quot;max_tokens&amp;quot;: 4096, &amp;quot;timeout&amp;quot;: 60000}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gemini&lt;/strong&gt;: &lt;code&gt;{&amp;quot;temperature&amp;quot;: 0.8, &amp;quot;maxOutputTokens&amp;quot;: 2048, &amp;quot;topP&amp;quot;: 0.95}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DeepSeek&lt;/strong&gt;: &lt;code&gt;{&amp;quot;temperature&amp;quot;: 0.5, &amp;quot;top_p&amp;quot;: 0.9, &amp;quot;frequency_penalty&amp;quot;: 0.1}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more detailed information about &lt;code&gt;llmParams&lt;/code&gt; configuration, please refer to the &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/llm-params-guide.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LLM Parameters Configuration Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;method-2-via-environment-variables&#34;&gt;Method 2: Via Environment Variables
&lt;/h3&gt;&lt;p&gt;Configure environment variables through the &lt;code&gt;-e&lt;/code&gt; parameter when deploying with Docker:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_OPENAI_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_key
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_GEMINI_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_key
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_DEEPSEEK_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_key
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_ZHIPU_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_key
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_SILICONFLOW_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_key
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_CUSTOM_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_custom_api_key
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_CUSTOM_API_BASE_URL&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_custom_api_base_url
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;-e &lt;span class=&#34;nv&#34;&gt;VITE_CUSTOM_API_MODEL&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;your_custom_model_name
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;local-development&#34;&gt;Local Development
&lt;/h2&gt;&lt;p&gt;For detailed documentation, see &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/dev.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Development Documentation&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 1. Clone the project&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/linshenkx/prompt-optimizer.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; prompt-optimizer
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 2. Install dependencies&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pnpm install
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 3. Start development server&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pnpm dev               &lt;span class=&#34;c1&#34;&gt;# Main development command: build core/ui and run web app&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pnpm dev:web          &lt;span class=&#34;c1&#34;&gt;# Run web app only&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pnpm dev:fresh        &lt;span class=&#34;c1&#34;&gt;# Complete reset and restart development environment&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;-roadmap&#34;&gt;🗺️ Roadmap
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Basic feature development&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Web application release&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Chrome extension release&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Custom model support&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Multi-model support optimization&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Internationalization support&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For detailed project status, see &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/project-status.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Project Status Document&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;-related-documentation&#34;&gt;📖 Related Documentation
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/README.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Documentation Index&lt;/a&gt; - Index of all documentation&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/technical-development-guide.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Technical Development Guide&lt;/a&gt; - Technology stack and development specifications&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/llm-params-guide.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LLM Parameters Configuration Guide&lt;/a&gt; - Detailed guide for advanced LLM parameter configuration&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/project-structure.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Project Structure&lt;/a&gt; - Detailed project structure description&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/project-status.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Project Status&lt;/a&gt; - Current progress and plans&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/prd.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Product Requirements&lt;/a&gt; - Product requirements document&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/vercel_en.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Vercel Deployment Guide&lt;/a&gt; - Detailed instructions for Vercel deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;star-history&#34;&gt;Star History
&lt;/h2&gt;&lt;a href=&#34;https://star-history.com/#linshenkx/prompt-optimizer&amp;Date&#34;&gt;
 &lt;picture&gt;
   &lt;source media=&#34;(prefers-color-scheme: dark)&#34; srcset=&#34;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&amp;theme=dark&#34; /&gt;
   &lt;source media=&#34;(prefers-color-scheme: light)&#34; srcset=&#34;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&#34; /&gt;
   &lt;img alt=&#34;Star History Chart&#34; src=&#34;https://api.star-history.com/svg?repos=linshenkx/prompt-optimizer&amp;type=Date&#34; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;
&lt;h2 id=&#34;faq&#34;&gt;FAQ
&lt;/h2&gt;&lt;h3 id=&#34;api-connection-issues&#34;&gt;API Connection Issues
&lt;/h3&gt;&lt;h4 id=&#34;q1-why-cant-i-connect-to-the-model-service-after-configuring-the-api-key&#34;&gt;Q1: Why can&amp;rsquo;t I connect to the model service after configuring the API key?
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: Most connection failures are caused by &lt;strong&gt;Cross-Origin Resource Sharing (CORS)&lt;/strong&gt; issues. As this project is a pure frontend application, browsers block direct access to API services from different origins for security reasons. Model services will reject direct requests from browsers if CORS policies are not correctly configured.&lt;/p&gt;
&lt;h4 id=&#34;q2-how-to-solve-ollama-connection-issues&#34;&gt;Q2: How to solve Ollama connection issues?
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: Ollama fully supports the OpenAI standard interface, just configure the correct CORS policy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set environment variable &lt;code&gt;OLLAMA_ORIGINS=*&lt;/code&gt; to allow requests from any origin&lt;/li&gt;
&lt;li&gt;If issues persist, set &lt;code&gt;OLLAMA_HOST=0.0.0.0:11434&lt;/code&gt; to listen on any IP address&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;q3-how-to-solve-cors-issues-with-commercial-apis-such-as-nvidias-ds-api-bytedances-volcano-api&#34;&gt;Q3: How to solve CORS issues with commercial APIs (such as Nvidia&amp;rsquo;s DS API, ByteDance&amp;rsquo;s Volcano API)?
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: These platforms typically have strict CORS restrictions. Recommended solutions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use Vercel Proxy&lt;/strong&gt; (Convenient solution)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use the online version: &lt;a class=&#34;link&#34; href=&#34;https://prompt.always200.com&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;prompt.always200.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Or deploy to your own Vercel platform&lt;/li&gt;
&lt;li&gt;Check &amp;ldquo;Use Vercel Proxy&amp;rdquo; option in model settings&lt;/li&gt;
&lt;li&gt;Request flow: Browser → Vercel → Model service provider&lt;/li&gt;
&lt;li&gt;For detailed steps, please refer to the &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/docs/vercel_en.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Vercel Deployment Guide&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Use self-deployed API proxy service&lt;/strong&gt; (Reliable solution)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deploy open-source API aggregation/proxy tools like OneAPI&lt;/li&gt;
&lt;li&gt;Configure as custom API endpoint in settings&lt;/li&gt;
&lt;li&gt;Request flow: Browser → Proxy service → Model service provider&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;q4-what-are-the-drawbacks-or-risks-of-using-vercel-proxy&#34;&gt;Q4: What are the drawbacks or risks of using Vercel proxy?
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;: Using Vercel proxy may trigger risk control mechanisms of some model service providers. Some vendors may identify requests from Vercel as proxy behavior, thereby limiting or denying service. If you encounter this issue, we recommend using a self-deployed proxy service.&lt;/p&gt;
&lt;h2 id=&#34;-contributing&#34;&gt;🤝 Contributing
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Fork the repository&lt;/li&gt;
&lt;li&gt;Create a feature branch (&lt;code&gt;git checkout -b feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Commit your changes (&lt;code&gt;git commit -m &#39;Add some feature&#39;&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Push to the branch (&lt;code&gt;git push origin feature/AmazingFeature&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Open a Pull Request&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tip: When developing with Cursor tool, it is recommended to do the following before committing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use the &amp;ldquo;CodeReview&amp;rdquo; rule for review&lt;/li&gt;
&lt;li&gt;Check according to the review report format:
&lt;ul&gt;
&lt;li&gt;Overall consistency of changes&lt;/li&gt;
&lt;li&gt;Code quality and implementation method&lt;/li&gt;
&lt;li&gt;Test coverage&lt;/li&gt;
&lt;li&gt;Documentation completeness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimize based on review results before submitting&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;-contributors&#34;&gt;👏 Contributors
&lt;/h2&gt;&lt;p&gt;Thanks to all the developers who have contributed to this project!&lt;/p&gt;
&lt;a href=&#34;https://github.com/linshenkx/prompt-optimizer/graphs/contributors&#34;&gt;
  &lt;img src=&#34;https://contrib.rocks/image?repo=linshenkx/prompt-optimizer&#34; alt=&#34;Contributors&#34; /&gt;
&lt;/a&gt;
&lt;h2 id=&#34;-license&#34;&gt;📄 License
&lt;/h2&gt;&lt;p&gt;This project is licensed under the &lt;a class=&#34;link&#34; href=&#34;https://github.com/linshenkx/prompt-optimizer/blob/master/LICENSE&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MIT&lt;/a&gt; License.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;If this project is helpful to you, please consider giving it a Star ⭐️&lt;/p&gt;
&lt;h2 id=&#34;-contact-us&#34;&gt;👥 Contact Us
&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Submit an Issue&lt;/li&gt;
&lt;li&gt;Create a Pull Request&lt;/li&gt;
&lt;li&gt;Join the discussion group&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Powerfule LLM Tool By Google : Gemini CLI</title>
        <link>https://ai.programnotes.cn/en/p/powerfule-llm-tool-by-google-gemini-cli/</link>
        <pubDate>Thu, 26 Jun 2025 00:00:00 +0000</pubDate>
        
        <guid>https://ai.programnotes.cn/en/p/powerfule-llm-tool-by-google-gemini-cli/</guid>
        <description>&lt;img src="https://ai.programnotes.cn/img/ai/cli/gemini-cli-1.png" alt="Featured image of post Powerfule LLM Tool By Google : Gemini CLI" /&gt;&lt;p&gt;Core:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Command-line AI workflow tool that connects to tools and understands code&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supports querying/editing large codebases and generating apps from PDFs/sketches&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Includes automation capabilities and MCP server integration for enhanced functionality&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;img src=&#34;https://github.com/google-gemini/gemini-cli/actions/workflows/ci.yml/badge.svg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemini CLI CI&#34;
	
	
&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ai.programnotes.cn/img/ai/cli/gemini-cli-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;Gemini CLI Screenshot&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;This repository contains the Gemini CLI, a command-line AI workflow tool that connects to your
tools, understands your code and accelerates your workflows.&lt;/p&gt;
&lt;p&gt;With the Gemini CLI you can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Query and edit large codebases in and beyond Gemini&amp;rsquo;s 1M token context window.&lt;/li&gt;
&lt;li&gt;Generate new apps from PDFs or sketches, using Gemini&amp;rsquo;s multimodal capabilities.&lt;/li&gt;
&lt;li&gt;Automate operational tasks, like querying pull requests or handling complex rebases.&lt;/li&gt;
&lt;li&gt;Use tools and MCP servers to connect new capabilities, including &lt;a class=&#34;link&#34; href=&#34;https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio/tree/main/experiments/mcp-genmedia&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;media generation with Imagen,
Veo or Lyria&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ground your queries with the &lt;a class=&#34;link&#34; href=&#34;https://ai.google.dev/gemini-api/docs/grounding&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google Search&lt;/a&gt;
tool, built in to Gemini.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;quickstart&#34;&gt;Quickstart
&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prerequisites:&lt;/strong&gt; Ensure you have &lt;a class=&#34;link&#34; href=&#34;https://nodejs.org/en/download&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Node.js version 18&lt;/a&gt; or higher installed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Run the CLI:&lt;/strong&gt; Execute the following command in your terminal:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;npx https://github.com/google-gemini/gemini-cli
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Or install it with:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;npm install -g @google/gemini-cli
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gemini
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pick a color theme&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Authenticate:&lt;/strong&gt; When prompted, sign in with your personal Google account. This will grant you up to 60 model requests per minute and 1,000 model requests per day using Gemini.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You are now ready to use the Gemini CLI!&lt;/p&gt;
&lt;h3 id=&#34;for-advanced-use-or-increased-limits&#34;&gt;For advanced use or increased limits:
&lt;/h3&gt;&lt;p&gt;If you need to use a specific model or require a higher request capacity, you can use an API key:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Generate a key from &lt;a class=&#34;link&#34; href=&#34;https://aistudio.google.com/apikey&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Google AI Studio&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Set it as an environment variable in your terminal. Replace &lt;code&gt;YOUR_API_KEY&lt;/code&gt; with your generated key.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;export&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;GEMINI_API_KEY&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;YOUR_API_KEY&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For other authentication methods, including Google Workspace accounts, see the &lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/authentication.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;authentication&lt;/a&gt; guide.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples
&lt;/h2&gt;&lt;p&gt;Once the CLI is running, you can start interacting with Gemini from your shell.&lt;/p&gt;
&lt;p&gt;You can start a project from a new directory:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; new-project/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gemini
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Write me a Gemini Discord bot that answers questions using a FAQ.md file I will provide
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Or work with an existing project:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git clone https://github.com/google-gemini/gemini-cli
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; gemini-cli
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;gemini
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Give me a summary of all of the changes that went in yesterday
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;next-steps&#34;&gt;Next steps
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Learn how to &lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/blob/main/CONTRIBUTING.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;contribute to or build from the source&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Explore the available &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/blob/main/docs/cli/commands.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CLI Commands&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;If you encounter any issues, review the &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/blob/main/docs/troubleshooting.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Troubleshooting guide&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;For more comprehensive documentation, see the &lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/blob/main/docs/index.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;full documentation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Take a look at some &lt;a class=&#34;link&#34; href=&#34;#popular-tasks&#34; &gt;popular tasks&lt;/a&gt; for more inspiration.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;troubleshooting&#34;&gt;Troubleshooting
&lt;/h3&gt;&lt;p&gt;Head over to the &lt;a class=&#34;link&#34; href=&#34;https://github.com/google-gemini/gemini-cli/blob/main/docs/troubleshooting.md&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;troubleshooting&lt;/a&gt; guide if you&amp;rsquo;re
having issues.&lt;/p&gt;
&lt;h2 id=&#34;popular-tasks&#34;&gt;Popular tasks
&lt;/h2&gt;&lt;h3 id=&#34;explore-a-new-codebase&#34;&gt;Explore a new codebase
&lt;/h3&gt;&lt;p&gt;Start by &lt;code&gt;cd&lt;/code&gt;ing into an existing or newly-cloned repository and running &lt;code&gt;gemini&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Describe the main pieces of this system&amp;#39;s architecture.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; What security mechanisms are in place?
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;work-with-your-existing-code&#34;&gt;Work with your existing code
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Implement a first draft for GitHub issue #123.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Help me migrate this codebase to the latest version of Java. Start with a plan.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;automate-your-workflows&#34;&gt;Automate your workflows
&lt;/h3&gt;&lt;p&gt;Use MCP servers to integrate your local system tools with your enterprise collaboration suite.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Make me a slide deck showing the git history from the last 7 days, grouped by feature and team member.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Make a full-screen web app for a wall display to show our most interacted-with GitHub issues.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;interact-with-your-system&#34;&gt;Interact with your system
&lt;/h3&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Convert all the images in this directory to png, and rename them to use dates from the exif data.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-text&#34; data-lang=&#34;text&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; Organise my PDF invoices by month of expenditure.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
